{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "391ff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b039738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Using OS library to call CLI commands in Python\n",
    "# os.system(\"snscrape --jsonl --max-results 5000 --since 2020-06-01 twitter-search 'business until:2020-06-30' > June_text-query-tweets_biz.json\")\n",
    "\n",
    "class TweetScrapper():\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         raw_tweet_df = []\n",
    "        \n",
    "    def scrap(self, filename):\n",
    "        dates = pd.read_csv('./data/dates_sm.csv')\n",
    "\n",
    "        tweets=[]\n",
    "        tweets_economics=[]\n",
    "        tweets_biz=[]\n",
    "        tweets_finance=[]\n",
    "        for idx, row in dates.iterrows():\n",
    "            dt1, dt2 =row[0].split(' ')\n",
    "\n",
    "            keyword1 = \"economics since:{} until:{}\".format(dt1, dt2)\n",
    "            keyword2 = \"business since:{} until:{}\".format(dt1, dt2)\n",
    "            keyword3 = \"financ since:{} until:{}\".format(dt1, dt2)\n",
    "\n",
    "            # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "            for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword1).get_items()):\n",
    "                if i>1500:\n",
    "                    break\n",
    "                tweets_economics.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "                tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "\n",
    "\n",
    "            for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword2).get_items()):\n",
    "                if i>1500:\n",
    "                    break\n",
    "                tweets_biz.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "                tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "\n",
    "            for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword3).get_items()):\n",
    "                if i>1500:\n",
    "                    break\n",
    "                tweets_finance.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "                tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.lang])\n",
    "\n",
    "        # Creating a dataframe from the tweets list above\n",
    "        tweets_df1= pd.DataFrame(tweets_economics, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'likeCount', 'retweetCount', 'lang'])\n",
    "        tweets_df2= pd.DataFrame(tweets_biz, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'likeCount', 'retweetCount', 'lang'])\n",
    "        tweets_df3= pd.DataFrame(tweets_finance, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'likeCount', 'retweetCount', 'lang'])\n",
    "\n",
    "        tweets_df= pd.DataFrame(tweets, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'likeCount', 'retweetCount', 'lang'])\n",
    "        tweets_df.to_csv('./tweet_data/{}'.format(filename), encoding='utf-8', index=False)\n",
    "        return tweets_df \n",
    "\n",
    "    def tweet_to_dataFrame(self, filename):\n",
    "        raw_tweet_df = pd.read_csv(\"./tweet_data/{}\".format(filename))\n",
    "        raw_tweet_df[\"Datetime\"] =  pd.to_datetime(raw_tweet_df.Datetime, infer_datetime_format=True)\n",
    "        raw_tweet_df[\"Text\"] = raw_tweet_df[\"Text\"].astype(str)\n",
    "        raw_tweet_df['date'] = raw_tweet_df['Datetime'].dt.date\n",
    "        raw_tweet_df['time'] = raw_tweet_df['Datetime'].dt.time\n",
    "        raw_tweet_df['month'] = raw_tweet_df['Datetime'].dt.strftime(\"%m\")\n",
    "        raw_tweet_df['year'] = raw_tweet_df['Datetime'].dt.strftime(\"%y\")\n",
    "        raw_tweet_df['period'] = raw_tweet_df[['year', 'month']].apply(lambda x: '-'.join(x), axis=1)\n",
    "        raw_tweet_df = raw_tweet_df[raw_tweet_df.lang == 'en']\n",
    "        return raw_tweet_df\n",
    "    \n",
    "    def pickle_tweets(self, tweets_df, filename):\n",
    "        outfile = open(filename,'wb')\n",
    "        pickle.dump(tweets_df,outfile)\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323eb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet_df = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = 'tweets.csv'\n",
    "    tweet_scrapper = TweetScrapper() \n",
    "    tweets_df = tweet_scrapper.scrap(filename)\n",
    "    raw_tweet_df = tweet_scrapper.tweet_to_dataFrame(filename)\n",
    "    tweet_scrapper.pickle_tweets(raw_tweet_df, \"raw_tweet_pickle.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd092b2d4e8b25642bb78c007d7a6f40d2ec1a44635e9e21bb5f68c2c2936c06aab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
